{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Customer Churn\n",
    "\n",
    "\n",
    "### History\n",
    "Churn is a measurement of the percentage of accounts that cancel or choose not to renew their subscriptions. A high churn rate can negatively impact Monthly Recurring Revenue (MRR) and can also indicate dissatisfaction with a product or service.\n",
    "\n",
    "Churn is the measure of how many customers stop using a product. This can be measured based on actual usage or failure to renew (when the product is sold using a subscription model). Often evaluated for a specific period of time, there can be a monthly, quarterly, or annual churn rate.\n",
    "\n",
    "<h3 style=\"text-align:left;\">How is Churn Calculated? </h3>\n",
    "<p style = \"text-align:left;\">\n",
    "In its most simplistic form, the churn rate is the percentage of total customers that stop using/paying over a period of time. So, if there were 10,000 total customers in March and 1,000 of them stopped being customers, the monthly churn rate would be 10%.\n",
    "</p>\n",
    "<img src = \"https://www.productplan.com/uploads/Churn-Rate-1024x536.png\" style=\"width=500px;height:300px\"/>\n",
    "\n",
    "### Assignment:\n",
    "\n",
    "Build a Machine Learning Pipeline, to engineer the features in the data set and predict the next leaver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# to handle datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to divide train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# to build the models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# to evaluate the models\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# to persist the model and the scaler\n",
    "import joblib\n",
    "\n",
    "# to visualise al the columns in the dataframe\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data - it is available open source and online\n",
    "\n",
    "data = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast target variable to int\n",
    "\n",
    "data['Churn'] = data['Churn'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast TotalCharges to float\n",
    "\n",
    "data['TotalCharges'] = pd.to_numeric(data['TotalCharges'],errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary variables\n",
    "\n",
    "data.drop(labels=['customerID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "### Find numerical and categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_num = ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "vars_cat = ['gender', 'Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'Contract', \n",
    "            'DeviceProtection', 'InternetService', 'MultipleLines', 'OnlineBackup', 'OnlineSecurity', \n",
    "            'PaymentMethod', 'StreamingMovies', 'StreamingTV', 'TechSupport']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of numerical variables: {}'.format(len(vars_num)))\n",
    "print('Number of categorical variables: {}'.format(len(vars_cat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find missing values in variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first in numerical variables\n",
    "\n",
    "data[vars_num].isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now in categorical variables\n",
    "\n",
    "data[vars_cat].isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine cardinality of categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[vars_cat].nunique(dropna=False).sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the distribution of numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[vars_num].hist(bins=30, figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('Churn', axis=1),  # predictors\n",
    "    data['Churn'],  # target\n",
    "    test_size=0.2,  # percentage of obs in test set\n",
    "    random_state=0)  # seed to ensure reproducibility\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in Missing data in numerical variables:\n",
    "\n",
    "- Add a binary missing indicator\n",
    "- Fill NA in original variable with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add missing indicator\n",
    "X_train['TotalCharges_NA'] = np.where(X_train['TotalCharges'].isnull(), 1, 0)\n",
    "X_test[['TotalCharges_NA']] = np.where(X_test['TotalCharges'].isnull(), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['TotalCharges'].fillna(0, inplace=True)\n",
    "X_test['TotalCharges'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform one hot encoding of categorical variables into k-1 binary variables\n",
    "\n",
    "- k-1, means that if the variable contains 9 different categories, we create 8 different binary variables\n",
    "- Remember to drop the original categorical variable (the one with the strings) after the encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in vars_cat:    \n",
    "    \n",
    "    # to create the binary variables, we use get_dummies from pandas    \n",
    "    \n",
    "    X_train = pd.concat([X_train, \n",
    "                         pd.get_dummies(X_train[var], prefix=var, drop_first=True)], \n",
    "                         axis=1)    \n",
    "    \n",
    "    X_test = pd.concat([X_test, \n",
    "                        pd.get_dummies(X_test[var], prefix=var, drop_first=True)], \n",
    "                        axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(labels=vars_cat, axis=1, inplace=True)\n",
    "X_test.drop(labels=vars_cat, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the variables\n",
    "\n",
    "- Use the standard scaler from Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [c  for c in X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#  fit  the scaler to the train set\n",
    "scaler.fit(X_train[variables]) \n",
    "\n",
    "# transform the train and test set\n",
    "X_train = scaler.transform(X_train[variables])\n",
    "\n",
    "X_test = scaler.transform(X_test[variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# How to Treat Imbalanced Datasets\n",
    "\n",
    "There are many ways of dealing with imbalanced data. We will focus in the following approaches:\n",
    "\n",
    "1. Oversampling - `SMOTE`\n",
    "2. Upsampling & Downsampling - `sklearn.utils.resample`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.utils import resample\n",
    "# from imblearn.over_sampling import SMOTE \n",
    "\n",
    "# # Upsample minority class\n",
    "# X_train_u, y_train_u = resample(X_train[y_train == 1],\n",
    "#                                 y_train[y_train == 1],\n",
    "#                                 replace=True,\n",
    "#                                 n_samples=X_train[y_train == 0].shape[0],\n",
    "#                                 random_state=1)\n",
    "# X_train_u = np.concatenate((X_train[y_train == 0], X_train_u))\n",
    "# y_train_u = np.concatenate((y_train[y_train == 0], y_train_u))\n",
    "\n",
    "\n",
    "\n",
    "# # Downsample majority class\n",
    "# X_train_d, y_train_d = resample(X_train[y_train == 0],\n",
    "#                                 y_train[y_train == 0],\n",
    "#                                 replace=True,\n",
    "#                                 n_samples=X_train[y_train == 1].shape[0],\n",
    "#                                 random_state=1)\n",
    "# X_train_d = np.concatenate((X_train[y_train == 1], X_train_d))\n",
    "# y_train_d = np.concatenate((y_train[y_train == 1], y_train_d))\n",
    "\n",
    "\n",
    "\n",
    "# # Upsample using SMOTE\n",
    "# sm = SMOTE(random_state=12, sampling_strategy = 1.0)\n",
    "# X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# print(\"Downsampled shape:\", X_train_d.shape, y_train_d.shape)\n",
    "# print(\"Original shape:\", X_train.shape, y_train.shape)\n",
    "# print(\"Upsampled shape:\", X_train_u.shape, y_train_u.shape)\n",
    "# print (\"SMOTE sample shape:\", X_train_sm.shape, y_train_sm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# # Create the Original, Upsampled, and Downsampled training sets\n",
    "# methods_data = {\"Original\": (X_train, y_train),\n",
    "#                 \"Upsampled\": (X_train_u, y_train_u),\n",
    "#                 \"Downsampled\": (X_train_d, y_train_d),\n",
    "#                 \"SMOTE\":(X_train_sm, y_train_sm)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# # Loop through each type of training sets and apply 5-Fold CV using Logistic Regression\n",
    "# # By default in cross_val_score StratifiedCV is used\n",
    "# for method in methods_data.keys():\n",
    "#     lr_results = cross_val_score(LogisticRegression(), \n",
    "#                                  methods_data[method][0], \n",
    "#                                  methods_data[method][1], \n",
    "#                                  cv=5, \n",
    "#                                  scoring='f1')\n",
    "#     print(f\"The best F1 Score for {method} data:\")\n",
    "#     print (lr_results.mean())\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Logistic Regression model\n",
    "\n",
    "- Set the regularization parameter to 0.0005\n",
    "- Set the seed to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the model\n",
    "# remember to set the random_state / seed\n",
    "\n",
    "model = LogisticRegression(C=0.0005, random_state=0)\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions and evaluate model performance\n",
    "\n",
    "Determine:\n",
    "- roc-auc\n",
    "- accuracy\n",
    "\n",
    "**Important, remember that to determine the accuracy, you need the outcome 0, 1, referring to survived or not. But to determine the roc-auc you need the probability of survival.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test set\n",
    "class_ = model.predict(X_train)\n",
    "pred = model.predict_proba(X_train)[:,1]\n",
    "\n",
    "# determine mse and rmse\n",
    "print('train roc-auc: {}'.format(roc_auc_score(y_train, pred)))\n",
    "print('train accuracy: {}'.format(accuracy_score(y_train, class_)))\n",
    "print()\n",
    "\n",
    "# make predictions for test set\n",
    "class_ = model.predict(X_test)\n",
    "pred = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# determine mse and rmse\n",
    "print('test roc-auc: {}'.format(roc_auc_score(y_test, pred)))\n",
    "print('test accuracy: {}'.format(accuracy_score(y_test, class_)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "```\n",
    "train roc-auc: 0.8410141283341551\n",
    "train accuracy: 0.7816826411075612\n",
    "\n",
    "test roc-auc: 0.8180757423881719\n",
    "test accuracy: 0.7693399574166075\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Well done\n",
    "\n",
    "**Keep this code safe, as we will use this notebook later on, to build production code, in our next assignement!!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
