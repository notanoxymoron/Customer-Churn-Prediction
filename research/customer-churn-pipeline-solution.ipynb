{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Customer Churn\n",
    "\n",
    "\n",
    "### History\n",
    "Churn is a measurement of the percentage of accounts that cancel or choose not to renew their subscriptions. A high churn rate can negatively impact Monthly Recurring Revenue (MRR) and can also indicate dissatisfaction with a product or service.\n",
    "\n",
    "Churn is the measure of how many customers stop using a product. This can be measured based on actual usage or failure to renew (when the product is sold using a subscription model). Often evaluated for a specific period of time, there can be a monthly, quarterly, or annual churn rate.\n",
    "\n",
    "<h3 style=\"text-align:left;\">How is Churn Calculated? </h3>\n",
    "<p style = \"text-align:left;\">\n",
    "In its most simplistic form, the churn rate is the percentage of total customers that stop using/paying over a period of time. So, if there were 10,000 total customers in March and 1,000 of them stopped being customers, the monthly churn rate would be 10%.\n",
    "</p>\n",
    "<img src = \"https://www.productplan.com/uploads/Churn-Rate-1024x536.png\" style=\"width=500px;height:300px\"/>\n",
    "\n",
    "### Assignment:\n",
    "\n",
    "Build a Machine Learning Pipeline, to engineer the features in the data set and predict the next leaver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# to handle datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to divide train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# to build the models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# to evaluate the models\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# to persist the model and the scaler\n",
    "import joblib\n",
    "\n",
    "# pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# for the preprocessors\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# for imputation\n",
    "from feature_engine.imputation import (\n",
    "    CategoricalImputer,\n",
    "    AddMissingIndicator,\n",
    "    ArbitraryNumberImputer)\n",
    "\n",
    "# for encoding categorical variables\n",
    "from feature_engine.encoding import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data - it is available open source and online\n",
    "\n",
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3955, 20), (989, 20))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('Churn', axis=1),  # predictors\n",
    "    data['Churn'],  # target\n",
    "    test_size=0.2,  # percentage of obs in test set\n",
    "    random_state=0)  # seed to ensure reproducibility\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast target variable to int\n",
    "\n",
    "data['Churn'] = data['Churn'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast TotalCharges to float\n",
    "\n",
    "data['TotalCharges'] = pd.to_numeric(data['TotalCharges'],errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary variables\n",
    "\n",
    "data.drop(labels=['customerID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of variables to be used in the pipeline's transformers\n",
    "\n",
    "NUMERICAL_VARS_WITH_NA = ['TotalCharges']\n",
    "\n",
    "CATEGORICAL_VARIABLES = ['gender', 'Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'Contract', \n",
    "                         'DeviceProtection', 'InternetService', 'MultipleLines', 'OnlineBackup', 'OnlineSecurity', \n",
    "                         'PaymentMethod', 'StreamingMovies', 'StreamingTV', 'TechSupport']\n",
    "\n",
    "FEATURES = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure', 'PhoneService', 'MultipleLines', \n",
    "            'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', \n",
    "            'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'MonthlyCharges', 'TotalCharges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUMERICAL_VARIABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3955, 19), (989, 19))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('Churn', axis=1),  # predictors\n",
    "    data['Churn'],  # target\n",
    "    test_size=0.2,  # percentage of obs in test set\n",
    "    random_state=0)  # seed to ensure reproducibility\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               object\n",
       "SeniorCitizen         int64\n",
       "Partner              object\n",
       "Dependents           object\n",
       "tenure                int64\n",
       "PhoneService         object\n",
       "MultipleLines        object\n",
       "InternetService      object\n",
       "OnlineSecurity       object\n",
       "OnlineBackup         object\n",
       "DeviceProtection     object\n",
       "TechSupport          object\n",
       "StreamingTV          object\n",
       "StreamingMovies      object\n",
       "Contract             object\n",
       "PaperlessBilling     object\n",
       "PaymentMethod        object\n",
       "MonthlyCharges      float64\n",
       "TotalCharges        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "- Add a binary missing indicator to numerical variables with missing data\n",
    "- Fill NA in original numerical variable with 0\n",
    "- Perform One hot encoding\n",
    "- Scale features with standard scaler\n",
    "- Fit a Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the pipeline\n",
    "churn_pipe = Pipeline([\n",
    "\n",
    "    # ===== IMPUTATION =====\n",
    "    # add missing indicator to numerical variables\n",
    "    ('missing_indicator', AddMissingIndicator(variables=NUMERICAL_VARS_WITH_NA)),\n",
    "\n",
    "    # impute numerical variables with 0\n",
    "    ('zero_imputation', ArbitraryNumberImputer(\n",
    "        arbitrary_number=0, variables=NUMERICAL_VARS_WITH_NA)),\n",
    "    \n",
    "    \n",
    "    # ===== ENCODING ======\n",
    "    # encode categorical variables using one hot encoding into k-1 variables\n",
    "    ('categorical_encoder', OneHotEncoder(\n",
    "        drop_last=True, variables=CATEGORICAL_VARIABLES)),\n",
    "    \n",
    "    \n",
    "    # ===== SCALING ======\n",
    "    # scale the training data\n",
    "    ('scaler', StandardScaler()),\n",
    "\n",
    "    \n",
    "    # ===== PREDICTION ======\n",
    "    ('Logit', LogisticRegression(C=0.0005, random_state=0)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('missing_indicator',\n",
       "                 AddMissingIndicator(variables=['TotalCharges'])),\n",
       "                ('zero_imputation',\n",
       "                 ArbitraryNumberImputer(arbitrary_number=0,\n",
       "                                        variables=['TotalCharges'])),\n",
       "                ('categorical_encoder',\n",
       "                 OneHotEncoder(drop_last=True,\n",
       "                               variables=['gender', 'Partner', 'Dependents',\n",
       "                                          'PhoneService', 'PaperlessBilling',\n",
       "                                          'Contract', 'DeviceProtection',\n",
       "                                          'InternetService', 'MultipleLines',\n",
       "                                          'OnlineBackup', 'OnlineSecurity',\n",
       "                                          'PaymentMethod', 'StreamingMovies',\n",
       "                                          'StreamingTV', 'TechSupport'])),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('Logit', LogisticRegression(C=0.0005, random_state=0))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the pipeline\n",
    "churn_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions and evaluate model performance\n",
    "\n",
    "Determine:\n",
    "- roc-auc\n",
    "- accuracy\n",
    "\n",
    "**Important, remember that to determine the accuracy, you need the outcome 0, 1, referring to survived or not. But to determine the roc-auc you need the probability of survival.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train roc-auc: 0.8292801445867324\n",
      "train accuracy: 0.7623261694058154\n",
      "\n",
      "test roc-auc: 0.8332856924097801\n",
      "test accuracy: 0.7654196157735086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions for train set\n",
    "class_ = churn_pipe.predict(X_train)\n",
    "pred = churn_pipe.predict_proba(X_train)[:,1]\n",
    "\n",
    "# determine mse and rmse\n",
    "print('train roc-auc: {}'.format(roc_auc_score(y_train, pred)))\n",
    "print('train accuracy: {}'.format(accuracy_score(y_train, class_)))\n",
    "print()\n",
    "\n",
    "# make predictions for test set\n",
    "class_ = churn_pipe.predict(X_test)\n",
    "pred = churn_pipe.predict_proba(X_test)[:,1]\n",
    "\n",
    "# determine mse and rmse\n",
    "print('test roc-auc: {}'.format(roc_auc_score(y_test, pred)))\n",
    "print('test accuracy: {}'.format(accuracy_score(y_test, class_)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "train roc-auc: 0.8292801445867324\n",
    "train accuracy: 0.7623261694058154\n",
    "\n",
    "test roc-auc: 0.8332856924097801\n",
    "test accuracy: 0.7654196157735086\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    94.54\n",
       "1     5.46\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's plot the predicted sale prices\n",
    "round(pd.DataFrame(class_).value_counts(normalize=True) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['churn_pipe.joblib']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's save the scaler\n",
    "\n",
    "joblib.dump(churn_pipe, 'churn_pipe.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2099, 19)\n"
     ]
    }
   ],
   "source": [
    "# load the unseen / new dataset\n",
    "data = pd.read_csv('test.csv')\n",
    "\n",
    "data['Churn'] = data['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "data.drop(labels=['customerID'], axis=1, inplace=True)\n",
    "\n",
    "data['TotalCharges'] = pd.to_numeric(data['TotalCharges'],errors = 'coerce')\n",
    "\n",
    "data = data[FEATURES]\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_preds = churn_pipe.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    94.43\n",
       "1     5.57\n",
       "dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's plot the predicted sale prices\n",
    "round(pd.DataFrame(new_preds).value_counts(normalize=True) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Well done\n",
    "\n",
    "**Keep this code safe, as we will use this notebook later on, to build production code, in our next assignement!!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
